---
title: "Assignment 1 of STAT 5361"
author: "Ruoyu Jia, Xi Chen"
date: "`r format(Sys.time(), '%d %B %Y')`"
documentclass: article
papersize: letter
fontsize: 11pt
output:
  html_document: default
  pdf_document: default
abstract:
    Following the project template at the Data Science Lab we produce this document for the following toy problem.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## get output format in case something needs extra effort
outFormat <- knitr::opts_knit$get("rmarkdown.pandoc.to")

## specify global chunk options
knitr::opts_chunk$set(fig.width = 5, fig.height = 4, dpi = 300,
                      out.width = "90%", fig.align = "center")
require(kableExtra)
```


#  Math equations 


Consider approximation of the distribution function of $N(0,1)$,
$$
    \Phi(t)=\int_\infty^{t} \frac{1}{2\pi}e^\frac{-y^2}{2}~dy,(\#eq:cdf)
$$
by the Monte Carlo methods:
$$
\hat{\Phi}(t)=\frac{1}{n}\sum_{i=1}^n I(X_i\le{t}),
$$
 Here $X_i~'$s is iid $N(0,1)$ variables.

#  Table 
As $X_i~'$s is iid $N(0,1)$ variables, we make experiment with the approximation at $n\in\{10^2,10^3,10^4\}$ at $t\in\{0.0,0.67,0.84,1.28,1.65,2.32,2.58,3.09,3.72\}$ to form a table, which also includes the true value in order to be compared with.
```{r echo=FALSE}
x <- c(0.0,0.67,0.84,1.28,1.65,2.32,2.58,3.09,3.72)
y <- pnorm(x, mean = 0, sd=1)
n <- c(100,1000,10000)
f <- matrix(0, nrow=3, ncol=9)
for (i in 1:3) {
  
  z <- rnorm(n[i], mean=0, sd=1)
  for(j in 1:9){
    for (k in 1:n[i]){
      if (z[k]<=x[j]){
        f[i,j] <- 1+f[i,j]
      }
    }
    f[i,j] <- f[i,j]/n[i]
  }
}
f <- data.frame(f)
colnames(f) <- x
f <- rbind(f,y)
row.names(f) <- c(100,1000,10000,"true") 
knitr::kable(f)
```

#  Figure 
Based on the experiment above, we then repeat it 100 times and obtain box plots of the bias at all t.

```{r echo=FALSE}
for (m in 1:3){
  g <- rep(0,100*9)
  for (i in 1:100){
    z <- rnorm(n[m], mean=0, sd=1)
    for (j in 1:9){
      for (k in 1:n[m]){
        if (z[k]<=x[j]){
          g[(i-1)*9+j] <- 1+g[(i-1)*9+j]
        }
      }
      g[(i-1)*9+j] <- g[(i-1)*9+j]/n[m]
      g[(i-1)*9+j] <- g[(i-1)*9+j] - y[j] 
    }
  }
  x <- rep(x,100)
  g <- data.frame(bais=g,tvalue=x)
  boxplot(bais~tvalue,g,main=paste("n=",n[m]))
}
```

#  Conlusion
According to the table and box plots of the bias we can find that the result generated by the Monte Carlo methods will become more closed to the true value as the times of the experiment we repeat increase.

